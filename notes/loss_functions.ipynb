{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f98cbe41",
   "metadata": {},
   "source": [
    "# Loss Functions:\n",
    "\n",
    "In this notebook we describe commonly used **machine learning loss functions**, grouped by task. We provide the formal definitions as well as the formal definition and use cases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5142154a",
   "metadata": {},
   "source": [
    "## üìÇ Table of Contents\n",
    "\n",
    "1. [Regression Losses](#-regression-losses)\n",
    "2. [Classification Losses](#-classification-losses)\n",
    "3. [Probabilistic / Likelihood-based Losses](#-probabilistic--likelihood-based-losses)\n",
    "4. [References & Further Reading](#-references--further-reading)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edc7e52",
   "metadata": {},
   "source": [
    "\n",
    "## üìê Regression Losses\n",
    "\n",
    "Used when the output is continuous.\n",
    "\n",
    "| Loss Name         | Notation             | Notes                                     |\n",
    "|------------------|----------------------|-------------------------------------------|\n",
    "| Mean Squared Error (MSE) | \\( \\frac{1}{n} \\sum_i (y_i - \\hat{y}_i)^2 \\) | Sensitive to outliers                     |\n",
    "| Mean Absolute Error (MAE) | \\( \\frac{1}{n} \\sum_i |y_i - \\hat{y}_i| \\) | Robust to outliers                        |\n",
    "| Huber Loss        | Piecewise: quadratic & linear | Combines MSE and MAE benefits            |\n",
    "| Log-Cosh Loss     | \\( \\sum_i \\log(\\cosh(y_i - \\hat{y}_i)) \\) | Smooth and less sensitive to outliers     |\n",
    "| Quantile Loss     | Asymmetric penalties | Used in quantile regression               |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed1305f",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## üßæ Classification Losses\n",
    "\n",
    "Used when the output is a discrete label or probability distribution over classes.\n",
    "\n",
    "| Loss Name               | Formula / Intuition                       | Notes                                     |\n",
    "|------------------------|--------------------------------------------|-------------------------------------------|\n",
    "| Binary Cross Entropy    | \\( -\\sum y \\log(\\hat{y}) + (1-y)\\log(1-\\hat{y}) \\) | For binary classification                 |\n",
    "| Categorical Cross Entropy | \\( -\\sum y_i \\log(\\hat{y}_i) \\)         | For multiclass classification             |\n",
    "| Hinge Loss              | \\( \\max(0, 1 - y \\cdot \\hat{y}) \\)        | Used in SVMs                              |\n",
    "| Focal Loss              | Weighted cross-entropy with a modulating factor | Useful for class imbalance                |\n",
    "| Label Smoothing        | Smoothed targets in cross-entropy         | Improves generalization                   |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d9711b",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## üé≤ Probabilistic / Likelihood-based Losses\n",
    "\n",
    "Used in generative models, variational inference, and Bayesian methods.\n",
    "\n",
    "| Loss Name               | Description                              | Example Use Cases                         |\n",
    "|------------------------|------------------------------------------|-------------------------------------------|\n",
    "| Negative Log-Likelihood (NLL) | \\( -\\log p(y | \\hat{y}) \\)          | General-purpose likelihood loss           |\n",
    "| KL Divergence           | \\( \\sum p(x) \\log \\frac{p(x)}{q(x)} \\)  | Used in VAEs, distribution matching       |\n",
    "| Jensen-Shannon Divergence | Symmetrized KL                         | Stable variant, used in GANs              |\n",
    "| Evidence Lower Bound (ELBO) | Reconstruction - KL term            | Key in variational inference              |\n",
    "| Wasserstein Distance     | Measures distribution difference        | GAN training, optimal transport           |\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
