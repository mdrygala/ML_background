{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a680d7d",
   "metadata": {},
   "source": [
    "###  Machine Learning Paradigms\n",
    "\n",
    "Machine learning can be categorized into different paradigms depending on the type of data we have. In the following we will briefly list typical tasks and algorithms. For more information one can consult other documents. For now, we focus on the five core paradigms:\n",
    "\n",
    "1. **Supervised Learning**  \n",
    "   Goal: Learn a function $f$ from labeled input-output pairs.  \n",
    "   Typical tasks: The typical tasks include classification, where the $f$ has a discrete range, and regression, where $f$ has a continuous range.  \n",
    "   Models: Linear and Logistic Regression, Support Vector Machines (SVMs), Decision Trees, Neural Networks.\n",
    "\n",
    "2. **Unsupervised Learning**  \n",
    "   Goal: Discover patterns or structure in unlabeled data.  \n",
    "   Typical tasks: There are three main tasks. The first is clustering where we group the data so that alike inputs are placed together. The second task is dimensionality reduction where we try and reduce the number of features our input data has while losing as little information as possible. The third task is density estimation, which is a statistical method used to estimate the PDF of a random variable based upon observed data.  \n",
    "   Algorithms: \n",
    "      - Clustering: K-Means, DBSCAN, HDBSCAN, Gaussian Mixture Models (GMM).\n",
    "      - Dimensionality Reduction: PCA, t-SNE, UMAP, Autoencoders\n",
    "   \n",
    "\n",
    "3. **Self-Supervised Learning** \n",
    "   Goal: The goal is the same as in the case of supervised learning but we train our data on pseudo-labels generated from the data itself. \n",
    "   Example: masked language modeling, next word prediction, contrastive learning.  \n",
    "   Models: BERT, SimCLR, MoCo, BYOL.\n",
    "\n",
    "4. **Reinforcement Learning**  \n",
    "   Learn to make decisions by interacting with an environment to maximize long-term reward.  \n",
    "   Example tasks: game playing, robotics\n",
    "   \n",
    "\n",
    "5. **Semi-Supervised Learning**  \n",
    "   Combine a small amount of labeled data with a large amount of unlabeled data.  \n",
    "   Example: training a classifier when labeling is expensive.  \n",
    "   Techniques: Pseudo-labeling, consistency regularization, MixMatch.\n",
    "\n",
    "---\n",
    "\n",
    "Iâ€™ll expand on each paradigm in dedicated sections with examples, formal definitions, and code where helpful.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a23020",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
